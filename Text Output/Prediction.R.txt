> library(caret)

> script_directory <- dirname(rstudioapi::getActiveDocumentContext()$path)

> setwd(script_directory)

> house <- read.csv("house_data.csv")

> house$price_category <- cut(house$price,
+                             breaks = c(-Inf, quantile(house$price, 0.25),
+                               .... [TRUNCATED] 

> # Convert date variable to Date
> house$date <- as.Date(house$date, format = "%Y%m%dT%H%M%S")

> set.seed(123)

> # Use the new price_category variable in the data partitioning
> training_data <- createDataPartition(house$price_category, p = 0.80, list = FALSE)

> house.trn <- house[training_data, ]

> house.tst <- house[-training_data, ]

> # Specify the features (independent variables) you want to use for classification
> 
> #features <- c("bedrooms","bathrooms","bedrooms",)
> features .... [TRUNCATED] 

> ctrl <- trainControl(method = "cv", number = 10)

> # Introduce a complexity parameter (adjust the value as needed)
> # ... (previous code remains unchanged)
> 
> # Introduce a smaller complexity para .... [TRUNCATED] 

> tuneGrid <- expand.grid(cp = complexity_values)

> # Specify the new response variable (price_category) in the formula
> fit.cv <- train(price_category ~ ., data = house.trn[, c(features, "price_cate ..." ... [TRUNCATED] 

> # Predict on the test set
> pred <- predict(fit.cv, house.tst[, features])

> # Evaluate the confusion matrix
> confusionMatrix(table(house.tst$price_category, pred))
Confusion Matrix and Statistics

           pred
            Low Medium High Very High
  Low       726    326   22         6
  Medium    178    701  187        26
  High       17    414  459       185
  Very High   7     75  262       730

Overall Statistics
                                        
               Accuracy : 0.6054        
                 95% CI : (0.5907, 0.62)
    No Information Rate : 0.3508        
    P-Value [Acc > NIR] : < 2.2e-16     
                                        
                  Kappa : 0.4736        
                                        
 Mcnemar's Test P-Value : < 2.2e-16     

Statistics by Class:

                     Class: Low Class: Medium Class: High Class: Very High
Sensitivity              0.7823        0.4624      0.4935           0.7709
Specificity              0.8957        0.8606      0.8183           0.8980
Pos Pred Value           0.6722        0.6419      0.4270           0.6797
Neg Pred Value           0.9377        0.7476      0.8549           0.9332
Prevalence               0.2148        0.3508      0.2152           0.2192
Detection Rate           0.1680        0.1622      0.1062           0.1689
Detection Prevalence     0.2499        0.2527      0.2488           0.2486
Balanced Accuracy        0.8390        0.6615      0.6559           0.8344

> par(mfrow = c(1, 2), cex = 0.7)

> par(mfrow = c(1, 1), cex = 0.7, mar = c(5, 10, 4, 2) + 0.1)

> #plot(fit, uniform=TRUE,margin=0.2)
> #text(fit, use.n=TRUE, all=TRUE, cex=.8)
> print(fit.cv)
CART 

17292 samples
   17 predictor
    4 classes: 'Low', 'Medium', 'High', 'Very High' 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 15563, 15565, 15563, 15563, 15562, 15562, ... 
Resampling results across tuning parameters:

  cp     Accuracy   Kappa    
  0.010  0.6206338  0.4939424
  0.011  0.6156597  0.4872540
  0.012  0.6109762  0.4809926
  0.013  0.6087792  0.4780924
  0.014  0.6044996  0.4724499
  0.015  0.6042104  0.4720789
  0.016  0.6042104  0.4720789
  0.017  0.6042104  0.4720789
  0.018  0.6042104  0.4720789
  0.019  0.6042104  0.4720789
  0.020  0.6042104  0.4720789
  0.021  0.6042104  0.4720789
  0.022  0.6042104  0.4720789
  0.023  0.6042104  0.4720789
  0.024  0.6042104  0.4720789
  0.025  0.6042104  0.4720789
  0.026  0.6042104  0.4720789
  0.027  0.6042104  0.4720789
  0.028  0.6042104  0.4720789
  0.029  0.6042104  0.4720789
  0.030  0.6042104  0.4720789
  0.031  0.6042104  0.4720789
  0.032  0.6042104  0.4720789
  0.033  0.6042104  0.4720789
  0.034  0.6042104  0.4720789
  0.035  0.6042104  0.4720789
  0.036  0.6042104  0.4720789
  0.037  0.6042104  0.4720789
  0.038  0.6042104  0.4720789
  0.039  0.6042104  0.4720789
  0.040  0.6042104  0.4720789
  0.041  0.6042104  0.4720789
  0.042  0.6042104  0.4720789
  0.043  0.6012029  0.4680906
  0.044  0.6012029  0.4680906
  0.045  0.6012029  0.4680906
  0.046  0.5892909  0.4523037
  0.047  0.5781286  0.4374910
  0.048  0.5726920  0.4303002
  0.049  0.5673741  0.4232640
  0.050  0.5655821  0.4209106
  0.051  0.5485753  0.3984746
  0.052  0.5416368  0.3893450
  0.053  0.5327314  0.3776450
  0.054  0.5327314  0.3776450
  0.055  0.5327314  0.3776450
  0.056  0.5327314  0.3776450
  0.057  0.5327314  0.3776450
  0.058  0.5327314  0.3776450
  0.059  0.5327314  0.3776450
  0.060  0.5327314  0.3776450
  0.061  0.5327314  0.3776450
  0.062  0.5327314  0.3776450
  0.063  0.5327314  0.3776450
  0.064  0.5327314  0.3776450
  0.065  0.5327314  0.3776450
  0.066  0.5327314  0.3776450
  0.067  0.5327314  0.3776450
  0.068  0.5327314  0.3776450
  0.069  0.5327314  0.3776450
  0.070  0.5327314  0.3776450
  0.071  0.5327314  0.3776450
  0.072  0.5327314  0.3776450
  0.073  0.5327314  0.3776450
  0.074  0.5327314  0.3776450
  0.075  0.5327314  0.3776450
  0.076  0.5327314  0.3776450
  0.077  0.5327314  0.3776450
  0.078  0.5327314  0.3776450
  0.079  0.5327314  0.3776450
  0.080  0.5327314  0.3776450
  0.081  0.5327314  0.3776450
  0.082  0.5327314  0.3776450
  0.083  0.5327314  0.3776450
  0.084  0.5327314  0.3776450
  0.085  0.5327314  0.3776450
  0.086  0.5327314  0.3776450
  0.087  0.5327314  0.3776450
  0.088  0.5327314  0.3776450
  0.089  0.5327314  0.3776450
  0.090  0.5327314  0.3776450
  0.091  0.5327314  0.3776450
  0.092  0.5327314  0.3776450
  0.093  0.5327314  0.3776450
  0.094  0.5327314  0.3776450
  0.095  0.5327314  0.3776450
  0.096  0.5327314  0.3776450
  0.097  0.5327314  0.3776450
  0.098  0.5327314  0.3776450
  0.099  0.5327314  0.3776450
  0.100  0.5327314  0.3776450

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.01.

> plot(fit.cv)

> plot(fit.cv$finalModel, uniform=TRUE, margin = 0.2)

> text(fit.cv$finalModel, cex = .8)